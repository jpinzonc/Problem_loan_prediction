{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Classifier State Farm \n",
    "## Data Science Position Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline\n",
    "l_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 Uploading the data\n",
    "\n",
    "The data is from the Lending Club. For 2017, currently (November 2017) there are two files, one for each of the first two quarters of the year.\n",
    "\n",
    "Upload each file separately and merge it into a single pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uploading data into two dataframes\n",
    "data_loans = pd.read_csv('data_files/exercise_01_train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 101)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'HEAD'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.142889</td>\n",
       "      <td>-15.675620</td>\n",
       "      <td>3.583176</td>\n",
       "      <td>-22.397489</td>\n",
       "      <td>27.221894</td>\n",
       "      <td>-34.110924</td>\n",
       "      <td>-0.072829</td>\n",
       "      <td>-0.544444</td>\n",
       "      <td>0.997601</td>\n",
       "      <td>-2.691778</td>\n",
       "      <td>...</td>\n",
       "      <td>1.916575</td>\n",
       "      <td>5.240820</td>\n",
       "      <td>euorpe</td>\n",
       "      <td>2.431170</td>\n",
       "      <td>0.454074</td>\n",
       "      <td>-18.572032</td>\n",
       "      <td>-14.291524</td>\n",
       "      <td>0.178579</td>\n",
       "      <td>18.110170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-52.214630</td>\n",
       "      <td>5.847135</td>\n",
       "      <td>-10.902843</td>\n",
       "      <td>-14.132351</td>\n",
       "      <td>20.588574</td>\n",
       "      <td>36.107322</td>\n",
       "      <td>0.115023</td>\n",
       "      <td>0.276093</td>\n",
       "      <td>-0.699168</td>\n",
       "      <td>-0.972708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370941</td>\n",
       "      <td>-3.794542</td>\n",
       "      <td>asia</td>\n",
       "      <td>2.592326</td>\n",
       "      <td>31.921833</td>\n",
       "      <td>3.317139</td>\n",
       "      <td>10.037003</td>\n",
       "      <td>-1.930870</td>\n",
       "      <td>-3.486898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.718500</td>\n",
       "      <td>2.064334</td>\n",
       "      <td>12.394186</td>\n",
       "      <td>-18.667102</td>\n",
       "      <td>47.465504</td>\n",
       "      <td>-50.373658</td>\n",
       "      <td>0.253707</td>\n",
       "      <td>1.068968</td>\n",
       "      <td>2.939713</td>\n",
       "      <td>2.691218</td>\n",
       "      <td>...</td>\n",
       "      <td>1.449817</td>\n",
       "      <td>12.470532</td>\n",
       "      <td>asia</td>\n",
       "      <td>7.143821</td>\n",
       "      <td>9.401490</td>\n",
       "      <td>-10.604968</td>\n",
       "      <td>7.643215</td>\n",
       "      <td>-0.842198</td>\n",
       "      <td>-79.358236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-28.003111</td>\n",
       "      <td>8.565128</td>\n",
       "      <td>-8.592092</td>\n",
       "      <td>5.918960</td>\n",
       "      <td>-3.224154</td>\n",
       "      <td>78.315783</td>\n",
       "      <td>-0.879845</td>\n",
       "      <td>1.176889</td>\n",
       "      <td>-2.414752</td>\n",
       "      <td>0.589646</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.274733</td>\n",
       "      <td>3.484450</td>\n",
       "      <td>asia</td>\n",
       "      <td>-4.998195</td>\n",
       "      <td>-20.312810</td>\n",
       "      <td>14.818524</td>\n",
       "      <td>-9.180674</td>\n",
       "      <td>1.356972</td>\n",
       "      <td>14.475681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.703016</td>\n",
       "      <td>30.736353</td>\n",
       "      <td>-30.101857</td>\n",
       "      <td>-21.201140</td>\n",
       "      <td>-91.946233</td>\n",
       "      <td>-47.469246</td>\n",
       "      <td>-0.646831</td>\n",
       "      <td>-0.578398</td>\n",
       "      <td>0.980849</td>\n",
       "      <td>-1.426112</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.644261</td>\n",
       "      <td>4.082783</td>\n",
       "      <td>asia</td>\n",
       "      <td>-0.012556</td>\n",
       "      <td>-29.334324</td>\n",
       "      <td>1.734433</td>\n",
       "      <td>-12.262072</td>\n",
       "      <td>-0.043228</td>\n",
       "      <td>-19.003881</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          x0         x1         x2         x3         x4         x5        x6  \\\n",
       "0  10.142889 -15.675620   3.583176 -22.397489  27.221894 -34.110924 -0.072829   \n",
       "1 -52.214630   5.847135 -10.902843 -14.132351  20.588574  36.107322  0.115023   \n",
       "2  67.718500   2.064334  12.394186 -18.667102  47.465504 -50.373658  0.253707   \n",
       "3 -28.003111   8.565128  -8.592092   5.918960  -3.224154  78.315783 -0.879845   \n",
       "4  80.703016  30.736353 -30.101857 -21.201140 -91.946233 -47.469246 -0.646831   \n",
       "\n",
       "         x7        x8        x9  ...       x91        x92     x93       x94  \\\n",
       "0 -0.544444  0.997601 -2.691778  ...  1.916575   5.240820  euorpe  2.431170   \n",
       "1  0.276093 -0.699168 -0.972708  ...  0.370941  -3.794542    asia  2.592326   \n",
       "2  1.068968  2.939713  2.691218  ...  1.449817  12.470532    asia  7.143821   \n",
       "3  1.176889 -2.414752  0.589646  ... -3.274733   3.484450    asia -4.998195   \n",
       "4 -0.578398  0.980849 -1.426112  ... -0.644261   4.082783    asia -0.012556   \n",
       "\n",
       "         x95        x96        x97       x98        x99  y  \n",
       "0   0.454074 -18.572032 -14.291524  0.178579  18.110170  0  \n",
       "1  31.921833   3.317139  10.037003 -1.930870  -3.486898  0  \n",
       "2   9.401490 -10.604968   7.643215 -0.842198 -79.358236  0  \n",
       "3 -20.312810  14.818524  -9.180674  1.356972  14.475681  0  \n",
       "4 -29.334324   1.734433 -12.262072 -0.043228 -19.003881  0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TAIL'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>20.844737</td>\n",
       "      <td>-33.785846</td>\n",
       "      <td>-0.346804</td>\n",
       "      <td>-3.406866</td>\n",
       "      <td>34.771517</td>\n",
       "      <td>-57.951056</td>\n",
       "      <td>-0.288205</td>\n",
       "      <td>1.371940</td>\n",
       "      <td>3.335447</td>\n",
       "      <td>1.765670</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.985304</td>\n",
       "      <td>7.312132</td>\n",
       "      <td>asia</td>\n",
       "      <td>5.964857</td>\n",
       "      <td>-13.061671</td>\n",
       "      <td>-8.062604</td>\n",
       "      <td>16.618593</td>\n",
       "      <td>-3.609543</td>\n",
       "      <td>0.631066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1.666154</td>\n",
       "      <td>16.241028</td>\n",
       "      <td>12.623090</td>\n",
       "      <td>-6.168540</td>\n",
       "      <td>-10.650748</td>\n",
       "      <td>69.840299</td>\n",
       "      <td>-0.965011</td>\n",
       "      <td>-4.321631</td>\n",
       "      <td>3.071324</td>\n",
       "      <td>-0.209940</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.842786</td>\n",
       "      <td>3.563600</td>\n",
       "      <td>asia</td>\n",
       "      <td>4.895863</td>\n",
       "      <td>-1.342384</td>\n",
       "      <td>-10.275539</td>\n",
       "      <td>14.046990</td>\n",
       "      <td>-0.320440</td>\n",
       "      <td>46.051387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1.795836</td>\n",
       "      <td>-15.706685</td>\n",
       "      <td>1.009672</td>\n",
       "      <td>-0.887671</td>\n",
       "      <td>-11.580529</td>\n",
       "      <td>3.237055</td>\n",
       "      <td>0.541397</td>\n",
       "      <td>2.562310</td>\n",
       "      <td>-0.623586</td>\n",
       "      <td>3.300388</td>\n",
       "      <td>...</td>\n",
       "      <td>7.503255</td>\n",
       "      <td>-11.064043</td>\n",
       "      <td>america</td>\n",
       "      <td>6.783607</td>\n",
       "      <td>15.293008</td>\n",
       "      <td>-6.194035</td>\n",
       "      <td>-4.725605</td>\n",
       "      <td>-1.321478</td>\n",
       "      <td>27.836630</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>50.168318</td>\n",
       "      <td>-4.272643</td>\n",
       "      <td>2.409248</td>\n",
       "      <td>-11.697615</td>\n",
       "      <td>39.234827</td>\n",
       "      <td>31.353302</td>\n",
       "      <td>1.416008</td>\n",
       "      <td>1.825775</td>\n",
       "      <td>2.027886</td>\n",
       "      <td>-3.753114</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.411384</td>\n",
       "      <td>-17.587621</td>\n",
       "      <td>america</td>\n",
       "      <td>6.278226</td>\n",
       "      <td>-18.743967</td>\n",
       "      <td>-8.067506</td>\n",
       "      <td>5.258203</td>\n",
       "      <td>-2.623772</td>\n",
       "      <td>-15.550075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>-8.653274</td>\n",
       "      <td>10.572796</td>\n",
       "      <td>1.377445</td>\n",
       "      <td>-21.472814</td>\n",
       "      <td>-42.686853</td>\n",
       "      <td>28.893360</td>\n",
       "      <td>3.379456</td>\n",
       "      <td>-1.241659</td>\n",
       "      <td>-0.040278</td>\n",
       "      <td>0.612898</td>\n",
       "      <td>...</td>\n",
       "      <td>7.622624</td>\n",
       "      <td>-6.473851</td>\n",
       "      <td>asia</td>\n",
       "      <td>0.055730</td>\n",
       "      <td>-6.506186</td>\n",
       "      <td>12.434701</td>\n",
       "      <td>-6.001283</td>\n",
       "      <td>-5.340633</td>\n",
       "      <td>18.276723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x0         x1         x2         x3         x4         x5  \\\n",
       "39995  20.844737 -33.785846  -0.346804  -3.406866  34.771517 -57.951056   \n",
       "39996   1.666154  16.241028  12.623090  -6.168540 -10.650748  69.840299   \n",
       "39997   1.795836 -15.706685   1.009672  -0.887671 -11.580529   3.237055   \n",
       "39998  50.168318  -4.272643   2.409248 -11.697615  39.234827  31.353302   \n",
       "39999  -8.653274  10.572796   1.377445 -21.472814 -42.686853  28.893360   \n",
       "\n",
       "             x6        x7        x8        x9  ...       x91        x92  \\\n",
       "39995 -0.288205  1.371940  3.335447  1.765670  ... -2.985304   7.312132   \n",
       "39996 -0.965011 -4.321631  3.071324 -0.209940  ... -5.842786   3.563600   \n",
       "39997  0.541397  2.562310 -0.623586  3.300388  ...  7.503255 -11.064043   \n",
       "39998  1.416008  1.825775  2.027886 -3.753114  ... -1.411384 -17.587621   \n",
       "39999  3.379456 -1.241659 -0.040278  0.612898  ...  7.622624  -6.473851   \n",
       "\n",
       "           x93       x94        x95        x96        x97       x98  \\\n",
       "39995     asia  5.964857 -13.061671  -8.062604  16.618593 -3.609543   \n",
       "39996     asia  4.895863  -1.342384 -10.275539  14.046990 -0.320440   \n",
       "39997  america  6.783607  15.293008  -6.194035  -4.725605 -1.321478   \n",
       "39998  america  6.278226 -18.743967  -8.067506   5.258203 -2.623772   \n",
       "39999     asia  0.055730  -6.506186  12.434701  -6.001283 -5.340633   \n",
       "\n",
       "             x99  y  \n",
       "39995   0.631066  0  \n",
       "39996  46.051387  0  \n",
       "39997  27.836630  0  \n",
       "39998 -15.550075  0  \n",
       "39999  18.276723  1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_loans.shape, 'HEAD', data_loans.head())\n",
    "display('TAIL', data_loans.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loans.y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the columns with only NaN and or with large number of NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create df with number of NaN on each column\n",
    "use_col = pd.DataFrame(data_loans.isnull().sum().sort_values())\n",
    "use_col.reset_index(drop = False, inplace=True)\n",
    "use_col.columns = (['col_name','num_NaN'])\n",
    "use_col.num_NaN.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are not that many NAN's for a data set with 40K rows. \n",
    "____\n",
    "\n",
    "#### NAN Distribution\n",
    "Counting number of columns with NAN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_NANs\tNum_of_NANcols_Total\tNum_of_NANcols_range\n",
      "\t 5 \t\t 13 \t\t\t 13\n",
      "\t 10 \t\t 69 \t\t\t 56\n",
      "\t 15 \t\t 100 \t\t\t 31\n",
      "\t 20 \t\t 101 \t\t\t 1\n",
      "\t 25 \t\t 101 \t\t\t 0\n",
      "\t 50 \t\t 101 \t\t\t 0\n",
      "\t 75 \t\t 101 \t\t\t 0\n",
      "\t 100 \t\t 101 \t\t\t 0\n"
     ]
    }
   ],
   "source": [
    "numbers = [5, 10, 15, 20, 25, 50, 75, 100]\n",
    "print('Num_NANs\\tNum_of_NANcols_Total\\tNum_of_NANcols_range')\n",
    "counter = 0\n",
    "for pos, num in enumerate(numbers):\n",
    "    if counter == 0:\n",
    "        l1 = 0\n",
    "    else:\n",
    "        pos1 = pos - 1\n",
    "        num1 = numbers[pos1]\n",
    "        l1 = pd.DataFrame(data_loans.isnull().sum().sort_values()[data_loans.isnull().sum().sort_values()<num1]).shape[0]\n",
    "    l2 = pd.DataFrame(data_loans.isnull().sum().sort_values()[data_loans.isnull().sum().sort_values()<num]).shape[0]\n",
    "    counter = counter+1\n",
    "    print('\\t', num, '\\t\\t', l2, '\\t\\t\\t', l2 - l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\tNoNAN\n",
      "(40000, 101) (39199, 101)\n",
      "#################### \n",
      "pct_chage = -0.02\n"
     ]
    }
   ],
   "source": [
    "# Removing all NAN's impact\n",
    "data_loans2 = data_loans.dropna(axis=0)\n",
    "print('Original\\tNoNAN')\n",
    "print(data_loans.shape, data_loans2.shape)\n",
    "print(20*'#', '\\npct_chage = {}'.format(np.round((data_loans2.shape[0]/data_loans.shape[0]-1),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the NA's are not that widespread in the data, only afecting 801 (~2%) rows. \n",
    "\n",
    "The impact is similar to both 'y' categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre</th>\n",
       "      <th>post</th>\n",
       "      <th>pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31953</td>\n",
       "      <td>31318</td>\n",
       "      <td>-0.0199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8047</td>\n",
       "      <td>7881</td>\n",
       "      <td>-0.0206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pre   post  pct_change\n",
       "0  31953  31318     -0.0199\n",
       "1   8047   7881     -0.0206"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impact = pd.concat([data_loans.y.value_counts(), data_loans2.y.value_counts() ], 1)\n",
    "impact.columns =['pre', 'post']\n",
    "impact.loc[:,'pct_change'] = round(impact.post/impact.pre -1, 4)\n",
    "impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming the removal of the NAN in the second dataframe\n",
    "use_col2 = pd.DataFrame(data_loans2.isnull().sum().sort_values())\n",
    "use_col2.reset_index(drop = False, inplace=True)\n",
    "use_col2.columns = (['col_name','num_NaN'])\n",
    "use_col2.num_NaN.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_loan_df = data_loans2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature cleaning and selection\n",
    "\n",
    "### Target feature (loan_status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_loan_df.y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom functiones needed later\n",
    "def types_of_columns(df):\n",
    "    '''\n",
    "    This function determines the category of the columns and returns a tuple with 2 df with column names for\n",
    "    numeric types and object types\n",
    "    '''\n",
    "    non_num_cols = df.dtypes[df.dtypes == 'object']\n",
    "    float_cols   = df.dtypes[df.dtypes != 'object']\n",
    "    return non_num_cols, float_cols\n",
    "\n",
    "def column_checker (df1, df2, min_len):\n",
    "    '''\n",
    "    Check the contents of the provided columns in df1 and types in df2\n",
    "    If the column has more unique values than min_len, the function prints\n",
    "        column name, number of unique values, and an array with the unique values\n",
    "    '''\n",
    "    for col in range(0,len(df2)):\n",
    "        col = df2.index[col]\n",
    "        values = df1[col].unique()\n",
    "        if len(values) > min_len:\n",
    "            print('\\n{}\\n{}\\n{}'.format(col, len(values), values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkig data by column type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_types_original = types_of_columns(n_loan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x34    object\n",
       "x35    object\n",
       "x41    object\n",
       "x45    object\n",
       "x68    object\n",
       "x93    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_col_list = col_types_original[0]\n",
    "nn_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x34\n",
      "10\n",
      "['bmw' 'nissan' 'Honda' 'Toyota' 'volkswagon' 'tesla' 'chrystler' 'ford'\n",
      " 'mercades' 'chevrolet']\n",
      "\n",
      "x35\n",
      "8\n",
      "['wed' 'thur' 'thurday' 'wednesday' 'friday' 'tuesday' 'monday' 'fri']\n",
      "\n",
      "x41\n",
      "37116\n",
      "['$-54.1' '$-229.32' '$243.68' ... '$1215.91' '$-723.78' '$-426.49']\n",
      "\n",
      "x45\n",
      "10\n",
      "['0.0%' '0.01%' '-0.01%' '0.02%' '-0.02%' '-0.0%' '-0.03%' '0.03%' '0.04%'\n",
      " '-0.04%']\n",
      "\n",
      "x68\n",
      "12\n",
      "['Jun' 'July' 'May' 'Aug' 'Apr' 'Mar' 'Oct' 'sept.' 'Nov' 'Feb' 'Dev'\n",
      " 'January']\n",
      "\n",
      "x93\n",
      "3\n",
      "['euorpe' 'asia' 'america']\n"
     ]
    }
   ],
   "source": [
    "column_checker(n_loan_df, nn_col_list, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above print out:\n",
    "\n",
    "Six columns are currently labeled as non-numeric. \n",
    "\n",
    "Of these, x41 appears to be a price and should be converted to numeric. \n",
    "\n",
    "x45 while has numbers on it, it appears as it contains categories of a range, and does not appear to need corrections\n",
    "\n",
    "The other are categorical, but there are errors that need to be corrected. For example:\n",
    "\n",
    "Column x35 appears to be days of the week, and 'friday' and 'fri' should be the same. \n",
    "\n",
    "All columns need to be corrrected for these errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting x41 to numeric\n",
    "n_loan_df.loc[:,'x41'] = n_loan_df.x41.str.replace('$', \" \").astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting dates and other numbers into actual numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Fixing 'typos'\n",
    "#x34 to title - just cosmetic\n",
    "n_loan_df.loc[:,'x34'] = n_loan_df.x34.str[:3].str.upper()\n",
    "\n",
    "#x35 and x68 to 3 letter day format to fix situations like 'friday' and 'fri'\n",
    "n_loan_df.loc[:,'x35'] = n_loan_df.x35.str[:3].str.title().str.upper()\n",
    "n_loan_df.loc[:,'x68'] = n_loan_df.x68.str[:3].str.title().str.upper()\n",
    "n_loan_df.loc[:,'x68'] = np.where(n_loan_df.x68 == 'DEV', 'DEC', n_loan_df.x68)\n",
    "\n",
    "#x93 Europe appears to have a typo\n",
    "n_loan_df.loc[:,'x93'] = np.where(n_loan_df.x93 == 'euorpe', 'EUROPE', n_loan_df.x93.str.upper())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_checker(n_loan_df, types_of_columns(n_loan_df)[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_loan_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_col_list = types_of_columns(n_loan_df)[0].index\n",
    "\n",
    "row = 2\n",
    "col = 3\n",
    "\n",
    "fig, axs = pl.subplots(row, col, figsize=(20,10))\n",
    "fig.subplots_adjust(wspace=0.5, hspace=0.25)\n",
    "axs[1, 2].axis('off')\n",
    "\n",
    "for num, name in enumerate(nn_col_list):\n",
    "    y = n_loan_df[name]\n",
    "    hue = n_loan_df['y']\n",
    "    i = num%row\n",
    "    j = num%col\n",
    "    graph = sns.countplot(y = y, hue = hue, ax = axs[i,j], linewidth = 1.5)\n",
    "    graph.set_xlabel(name, fontsize=15)\n",
    "    graph.set_ylabel('', fontsize=1)\n",
    "    graph.tick_params(labelsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in nn_col_list:\n",
    "    series = n_loan_df.groupby([col, 'y'])['y'].count()\n",
    "    print ('\\n',series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(types_of_columns(n_loan_df)[1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col_list = types_of_columns(n_loan_df)[1].index.drop(['y'])\n",
    "for col in num_col_list:\n",
    "    length = len(n_loan_df[col].unique())\n",
    "    print (col, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_col_list = types_of_columns(n_loan_df)[1].index.drop('y')\n",
    "cor_df = pd.DataFrame()\n",
    "for i in range(0,len(num_col_list)):\n",
    "    cor_df = pd.concat([cor_df, n_loan_df[num_col_list[i]]],axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = pl.subplots(figsize=(20, 15))\n",
    "corr = cor_df.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(250, 15, as_cmap=True),\n",
    "            square=True, ax=ax, annot=True, vmin=0, vmax=1, linewidths=2, xticklabels=1, yticklabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_summary = pd.DataFrame(columns = ['column', 'max_corr', 'min_corr'])\n",
    "for col in corr.columns:\n",
    "    df = corr.drop(col)\n",
    "    df1 = {}\n",
    "    df1['column']   = [col]\n",
    "    df1['max_corr'] = [df[col].max()]\n",
    "    df1['min_corr'] = [df[col].min()]\n",
    "    cor_summary = pd.concat([cor_summary, pd.DataFrame.from_dict(df1)], 0)\n",
    "cor_summary.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_loan_df = n_loan_df.reset_index(drop = True)\n",
    "n_loans = n_loan_df.drop('y', 1)\n",
    "outliers_all = np.array([], dtype='int64')\n",
    "for column in types_of_columns(n_loans)[1].index:\n",
    "    Q1 = np.percentile(n_loans[column], 25)\n",
    "    Q3 = np.percentile(n_loans[column], 75)\n",
    "    step = (Q3 - Q1)*2\n",
    "    out_list_feat=list(n_loans[~((n_loans[column] >= Q1 - step) & (n_loans[column] <= Q3 + step))].index)\n",
    "    outliers_all = np.append(outliers_all, out_list_feat)\n",
    "\n",
    "from collections import Counter\n",
    "out_count = Counter(outliers_all)\n",
    "out_customer =[]\n",
    "for customer, count in out_count.items():\n",
    "    if count > 1:\n",
    "        out_customer.append(customer.astype(int))\n",
    "outliers  = list(sorted(out_customer))\n",
    "\n",
    "print(\"%d outliers found in more than one feature will be remove\" % len(outliers))\n",
    "n_loan_no_out = n_loan_df.drop(n_loan_df.index[outliers])\n",
    "print(n_loan_df.shape, n_loan_no_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_col_list = types_of_columns(n_loan_no_out)[1].index.drop('y')\n",
    "cor_df = pd.DataFrame()\n",
    "for i in range(0,len(num_col_list)):\n",
    "    cor_df = pd.concat([cor_df, n_loan_df[num_col_list[i]]],axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_summary = pd.DataFrame(columns = ['column', 'max_corr', 'min_corr'])\n",
    "for col in corr.columns:\n",
    "    df = corr.drop(col)\n",
    "    df1 = {}\n",
    "    df1['column']   = [col]\n",
    "    df1['max_corr'] = [df[col].max()]\n",
    "    df1['min_corr'] = [df[col].min()]\n",
    "    cor_summary = pd.concat([cor_summary, pd.DataFrame.from_dict(df1)], 0)\n",
    "cor_summary.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in (nn_col_list):\n",
    "    n_loan_no_out[col]=l_encoder.fit_transform(n_loan_no_out[col])\n",
    "n_loan_no_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_loan_no_out.shape)\n",
    "n_loan_no_out.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model\n",
    "#### Spliting the data for the model\n",
    "\n",
    "Spliting into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = n_loan_no_out['y'].values\n",
    "features = n_loan_no_out.drop(['y'], axis=1).values\n",
    "print ('Loans original data %d, target: %d, features: %d' % (n_loan_no_out.shape[0], target.shape[0], features.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an raw model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCTION FROM SKELEARN DOCUMENTATION WILL BE USED FOR THE CONFUSION MATRIX PLOT\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=pl.cm.Blues):\n",
    "    \"\"\" FROM SCIKIT LEARN DOCUMENTATION\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    pl.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    pl.title(title)\n",
    "    pl.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    pl.xticks(tick_marks, classes, rotation=45)\n",
    "    pl.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        pl.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    pl.tight_layout()\n",
    "    pl.ylabel('True label')\n",
    "    pl.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training, valdation, and testing subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=1)\n",
    "X_train, X_val, y_train, y_val   = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_val = sc.transform(X_val)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 14, kernel_initializer = 'uniform', activation = 'relu', input_dim = 100))\n",
    "classifier.add(Dense(units = 14, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model with the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Crossvalidation on validation set\n",
    "from keras.wrappers.scikit_learn import KerasClassifier # keras wrapper for sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def build_classifier():\n",
    "    classifier_cv = Sequential()\n",
    "    classifier_cv.add(Dense(units = 14, kernel_initializer = 'uniform', activation = 'relu', input_dim = 100))\n",
    "    classifier_cv.add(Dense(units = 14, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier_cv.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier_cv.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier_cv\n",
    "\n",
    "classifier_cv = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 10)\n",
    "accuracies = cross_val_score(estimator = classifier_cv, X = X_train, y = y_train, cv = 10)\n",
    "\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean cv accuracy = {:.4f}% +/- {:.4f}'.format(mean *100, variance *100) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on the validation set\n",
    "loss, accuracy = classifier.evaluate(X_val, y_val,batch_size=128, verbose=0)\n",
    "print(\"Accuracy = {:.4f}%, Loss = {:.4f}\".format(accuracy* 100, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def build_classifier_imp(optimizer):\n",
    "    classifier_op = Sequential()\n",
    "    classifier_op.add(Dense(units = 14, kernel_initializer = 'uniform', activation = 'relu', input_dim = 100))\n",
    "    classifier_op.add(Dense(units = 14, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier_op.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier_op.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier_op\n",
    "\n",
    "classifier_op = KerasClassifier(build_fn = build_classifier_imp)\n",
    "\n",
    "parameters = {'batch_size': [10, 30],\n",
    "              'epochs': [10, 20],\n",
    "              'optimizer': ['adam', 'rmsprop']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier_op,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (best_parameters, best_accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting and prediction with optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with optimize settings\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "classifier.save('data_files/classifier_opt.hdf5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on the validation set\n",
    "loss, accuracy = classifier.evaluate(X_val, y_val,batch_size=128, verbose=0)\n",
    "print(\"Accuracy = {:.4f}%, Loss = {:.4f}\".format(accuracy* 100, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting on the test set \n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on the test set\n",
    "loss, accuracy = classifier.evaluate(X_test, y_test,batch_size=128, verbose=0)\n",
    "print(\"Accuracy = {:.4f}%, Loss = {:.4f}\".format(accuracy* 100, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(8,8))\n",
    "plot_confusion_matrix(cnf_matrix, classes=n_loan_no_out.loan_status.unique(),\n",
    "                      cmap=pl.cm.Reds, normalize=False)\n",
    "\n",
    "\n",
    "pl.savefig('data_files/Conf_matrix_2017.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred.round(), average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_loan_df.loan_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
